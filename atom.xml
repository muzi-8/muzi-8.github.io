<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>muzi-8</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-08-09T12:19:46.953Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>muzi</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>CSAPP课程（Computer Systems A Programmer&#39;s Perspective)</title>
    <link href="http://yoursite.com/2018/08/09/CSAPP%E8%AF%BE%E7%A8%8B/"/>
    <id>http://yoursite.com/2018/08/09/CSAPP课程/</id>
    <published>2018-08-09T12:19:46.943Z</published>
    <updated>2018-08-09T12:19:46.953Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="Project" scheme="http://yoursite.com/categories/Project/"/>
    
    
      <category term="Computer Systems" scheme="http://yoursite.com/tags/Computer-Systems/"/>
    
  </entry>
  
  <entry>
    <title>机器学习的可解译性</title>
    <link href="http://yoursite.com/2018/07/31/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/"/>
    <id>http://yoursite.com/2018/07/31/机器学习的可解释性/</id>
    <published>2018-07-31T09:09:12.022Z</published>
    <updated>2017-08-31T01:30:38.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2018/07/31/机器学习的可解释性/timg.jpg" title="Machine Learning"><blockquote><p>Interpretation is the process of giving<br>explanations<br>解译性指的是给出可解释的过程</p></blockquote><p>即三个问题</p><ol><li>为什么要给出解译性？</li><li>通过什么途径给出可解释性呢？</li><li>我们又如何去评价这是一种好的可解释方法？</li></ol><h5 id="可解释模型的分类（既不是互相排斥-mutually-exclusive-的分类，也不是文献的罗列-exhaustive-list-）"><a href="#可解释模型的分类（既不是互相排斥-mutually-exclusive-的分类，也不是文献的罗列-exhaustive-list-）" class="headerlink" title="可解释模型的分类（既不是互相排斥(mutually exclusive)的分类，也不是文献的罗列(exhaustive list)）"></a>可解释模型的分类（既不是互相排斥(mutually exclusive)的分类，也不是文献的罗列(exhaustive list)）</h5><p>方法：</p><ol><li><p>搭建模型之前</p><ul><li>数据探索的可视（KMeans KNN 等聚类算法）</li></ul></li><li><p>搭建模型过程当中</p><ul><li>基于规则/基于属性(特征)</li><li>基于实例</li><li>从稀疏角度</li><li>从单调角度（借助制定区间形式定义函数变化的趋势（user specified lattice))</li></ul></li><li><p>给定模型之后(比如深度学习)</p><ul><li>敏感性分析，基于梯度的方法（sensitivity analysis）此方法来自金融风险（自变量与因变量关系）领域</li><li>模型的替换</li><li>隐层、中间层的观察</li></ul><p>评价<br>从不同角度去评价！可参考原文</p><p>Reference：</p><ol><li><a href="https://link.zhihu.com/?target=http://people.csail.mit.edu/beenkim/icml_tutorial.html" target="_blank" rel="noopener">Tutorial on Interpretable Machine Learning by Been Kim</a></li><li><a href="https://www.zhihu.com/question/60374968" target="_blank" rel="noopener">ICML 2017上哪些论文值得关注</a></li></ol></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;img src=&quot;/2018/07/31/机器学习的可解释性/timg.jpg&quot; title=&quot;Machine Learning&quot;&gt;
&lt;blockquote&gt;
&lt;p&gt;Interpretation is the process of giving&lt;br&gt;explanations&lt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>解析word文档表格</title>
    <link href="http://yoursite.com/2018/07/31/%E8%A7%A3%E6%9E%90word%E6%96%87%E6%A1%A3/"/>
    <id>http://yoursite.com/2018/07/31/解析word文档/</id>
    <published>2018-07-31T09:09:12.011Z</published>
    <updated>2018-05-14T15:15:10.000Z</updated>
    
    <content type="html"><![CDATA[<pre><code># -*- coding: utf-8 -*-# from __future__ import print_functionimport sysreload(sys)sys.setdefaultencoding(&apos;utf-8&apos;)import win32comfrom win32com.client import Dispatch, constantsw = win32com.client.Dispatch(&apos;Word.Application&apos;)w.Visible = 1w.Documents.Open( FileName = &apos;D:\muzi\\37.docx&apos;)  #路径不能存在中文doc = w.ActiveDocumentcount = doc.Tables.Count  #统计整个word文档有多少个表a = doc.Tables(1).rows.Count # 返回表格的行数b = doc.Tables(1).columns.Count # 返回表格的列数import collectionsContent = collections.OrderedDict()for num in range (count):    for i in range (doc.Tables(num+1).rows.Count):        key = re.sub(r&apos;\r\x07&apos;,&apos;&apos;,doc.Tables(num+1).Cell(Row= i+1,Column = 1).Range.Text) //正则化去除特殊符号        value = re.sub(r&apos;\r\07&apos;,&apos;&apos;,doc.Tables(num+1).Cell(Row=i+1,Column = 2).Range.Text)         Content[key] = value    filename = &apos;D:\muzi\m&apos;      import json    with open(filename+&apos;.json&apos;,&apos;a&apos;) as outfile:    //打开已存在的文件        json.dump(Content,outfile,ensure_ascii = False) //字典内容写入json文件中        outfile.write(&apos;\n&apos;)</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;pre&gt;&lt;code&gt;# -*- coding: utf-8 -*-
# from __future__ import print_function
import sys
reload(sys)
sys.setdefaultencoding(&amp;apos;utf-8&amp;apos;)

      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>opencv离线安装问题</title>
    <link href="http://yoursite.com/2018/07/31/opencv%E5%AE%89%E8%A3%85%E9%97%AE%E9%A2%98/"/>
    <id>http://yoursite.com/2018/07/31/opencv安装问题/</id>
    <published>2018-07-31T09:09:11.991Z</published>
    <updated>2018-04-24T04:11:06.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="step-0"><a href="#step-0" class="headerlink" title="step 0"></a>step 0</h3><p>下载源文件 opencv-2.4.11.zip<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ unzip opencv-2.4.11.zip</span><br></pre></td></tr></table></figure></p><p>在解压路径下面进行编译<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cmake CMakeLists.txt -DWITH_CUDA=ON -DCUDA_ARCH_BIN=<span class="string">"3.2"</span> -DCUDA_ARCH_PTX=<span class="string">""</span> -DBUILD_TESTS=OFF -DBUILD_PERF_TESTS=OFF -DBUILD_NEW_PYTHON_SUPPORT=ON</span><br><span class="line"></span><br><span class="line">make -j4</span><br></pre></td></tr></table></figure></p><a id="more"></a><p>报错0：<br><img src="/2018/07/31/opencv安装问题/161227210742477.png"><br>opencv与cuda8.0不兼容导致，～/opencv/modules/cudalegacy/src/graphcuts.cpp文件内容：<br><img src="/2018/07/31/opencv安装问题/161227210742478.png"><br>OK！重新编译</p><h3 id="step-1"><a href="#step-1" class="headerlink" title="step 1"></a>step 1</h3><p>安装源文件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ make install</span><br></pre></td></tr></table></figure></p><p>ok 安装成功！<br>opencv默认安装位置为“/usr/local”下lib、bin、include等目录</p><h3 id="step-2"><a href="#step-2" class="headerlink" title="step 2"></a>step 2</h3><p>使用 python import cv2<br>错误1：<br>没有此模块，需要将opencv安装的源文件下面编译生成的共享文件库cv2.so拷贝至使用的python 下面。<br>本人使用的python环境是 /home/muzi-18/anaconda2/lib/python2.7/site-packages<br>错误 2：<br>libstdc++so.6 version ‘GLIBCXX_3.4.21’not found<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cp /usr/lib/x86_64-linux-gnu/libstdc++.so.6  /home/muzi-18/anaconda2/lib/libstdc++.so.6</span><br></pre></td></tr></table></figure></p><p>ok!<br>python<br> import cv2<br>测试成功！</p><p>Reference：<a href="http://www.linuxidc.com/Linux/2016-12/138870.htm" target="_blank" rel="noopener">http://www.linuxidc.com/Linux/2016-12/138870.htm</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;step-0&quot;&gt;&lt;a href=&quot;#step-0&quot; class=&quot;headerlink&quot; title=&quot;step 0&quot;&gt;&lt;/a&gt;step 0&lt;/h3&gt;&lt;p&gt;下载源文件 opencv-2.4.11.zip&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ unzip opencv-2.4.11.zip&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;在解压路径下面进行编译&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;cmake CMakeLists.txt -DWITH_CUDA=ON -DCUDA_ARCH_BIN=&lt;span class=&quot;string&quot;&gt;&quot;3.2&quot;&lt;/span&gt; -DCUDA_ARCH_PTX=&lt;span class=&quot;string&quot;&gt;&quot;&quot;&lt;/span&gt; -DBUILD_TESTS=OFF -DBUILD_PERF_TESTS=OFF -DBUILD_NEW_PYTHON_SUPPORT=ON&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;make -j4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Software Install" scheme="http://yoursite.com/categories/Software-Install/"/>
    
    
      <category term="Linux" scheme="http://yoursite.com/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>写给自己的一封信</title>
    <link href="http://yoursite.com/2018/07/31/%E5%86%99%E7%BB%99%E8%87%AA%E5%B7%B1%E7%9A%84%E4%B8%80%E5%B0%81%E4%BF%A1/"/>
    <id>http://yoursite.com/2018/07/31/写给自己的一封信/</id>
    <published>2018-07-31T09:09:11.981Z</published>
    <updated>2018-08-09T13:12:23.511Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>十年饮冰, 难凉热血, 梦还在,黄苍终会眷顾.         –梁启超</p></blockquote><p>北京的周五依旧是行人匆匆,夹杂着兮兮小雨,更是显得匆忙与急促.打着雨伞赶着去实验室,继续完成自己调不完的bug,写不完的程序.真是应了实验室同学的调侃”沐风栉雨搞科研”.<br>惯例周五的实验室必定是空空荡荡,无意在微信朋友圈看到好友江转发了一篇关于NBA比赛报道的文章,若不是他配有文字描述”如果足够努力,最差的结果不就是大器晚成”, 还以为又是司空见惯的NBA球场上那些”飞禽猛兽”不可思议的表现.充满着疑问点开了由”虎扑体育”公众号推送的题为”你生涯最高光的时刻是总决赛MVP吗?而我,就是现在了”.看完文章之后,已然哭成一个傻逼样,心情久久不能平复.<br><a id="more"></a><br>文章讲述了一个主人公名叫”安德烈-英格拉姆”在发展联盟打了整整10年球,度过了长达10年之久的每年领着卑微的2.6W的年薪,同时兼职当家教补贴两个女儿的生活费,终于在自己32岁时迎来了NBA生涯首秀.他在赛后回忆说<strong>“这里的球场看起来更加明亮一些,太出乎意料了,我就是感觉到了一股电流流遍全身,太美妙了热情的观众,耀眼的灯光,这真的是一辈子一次的景象</strong><br>这不就是电影”当幸福来敲门”的克里斯活生生的例子啊!吓得我虎躯一震,生活中真有为梦想而坚持的人? 赶紧打开百度浏览器搜索了关键词<strong>“安德烈-英格拉姆”</strong>,有一篇知乎名为”如何评价「湖人与后卫安德烈-英格拉姆签约至本赛季结束」?”这个鲜活有生命力的运动员形象慢慢在我的脑海中丰富起来,认真看完了网友的所有评论,”大道至简”网友评论道</p><blockquote><p>我很尊重为了梦想在打拼的人们,看到魔术师和沃顿他们轻松的笑说”祝贺”,他激动的只会说”感谢”,我会想到千千万万个他们,像他一样,每天默默努力,终于有朝一日成功的那种激动带点傻呵呵的笑和不知所措,真心尊敬与祝福你,祝贺你的梦想实现,就像你的T恤上的一样”always in pursuit”! ,当你认真踏上球场的那一刻,请相信,全世界都在为你骄傲,加油!<br><img src="http://od2s78ez3.bkt.clouddn.com/18-4-13/81508159.jpg" alt=""></p></blockquote><p>正如毛姆小说”月亮与六便士”中的查尔斯先生,在追逐梦想的路上,他过得穷困潦倒,并且一再遭受命运的摧残,不同的是查尔斯先生到死都没有亲眼看到自己的一幅画能够价值连城,而安德烈-英格拉姆在自己32岁终于踏入了斯台普斯中心(Staples Center).实现了属于自己追逐了十年的梦想.正如书中所说:</p><blockquote><p>难道做自己最想做的事,生活在让你感到舒服的环境里,让你的内心得到安宁是糟践自己吗?难道成为年入上万英镑的外科医生,娶得如花美眷就算是成功吗?</p></blockquote><p>至于自己为什么会哭的一塌糊涂,或许只有相同经历的人才能深深的感受到安德烈的那种无奈与坚毅,对于自己而言,求学之路仍未结束,应该是到了深水区与艰难区,高中因为自己的后知后觉,虽然无心插柳考上了市重点中学,但依旧没能鲤鱼跃龙门,选择了fu读之路,就靠着”黑曼巴”精神顺利步入大学之门,进入大学的第一天目标就非常明确,一定要借着”西北农林科技大学”985这个平台跳出去,完成自己”梦想”,正如我所愿,4年的奋斗换来”中科院电子所”的直博入学书.<br>本科的专业是EE,如今要转向CS,其中的自卑与不知所措,让我一下子失去了方向,没有了曾经的优秀感,还好自己已经行动起来,凭借着自学能力与领悟能力,全方位的去弥补自己知识的不足与能力的欠缺,一切都还在路上,正如 吴军老师在”浪潮之巅”所讲:处在这个”Deep Learning”浪潮之中,要有所作为,不要再次成为观潮者. 不忘初心,砥砺前行!<br>最后以习总书记2018年在亚洲博鳌经济论坛的警句结束啰啰嗦嗦的文章</p><blockquote><p>积土而为山, 积水而为海,幸福和美好的未来不会自己出现,成功属于勇毅而笃行的人</p></blockquote><p>这不正好印证了我的两所大学的校训了嘛,不说了,赶紧去写程序…<br>注:<br>西北农林科技大学 校训 : 诚朴勇毅<br>中国科学院大学 校训: 博学笃志, 格物明德</p><p>Reference:<br><a href="https://www.washingtonpost.com/news/dc-sports-bog/wp/2018/04/10/after-a-decade-in-the-minors-this-32-year-old-finally-got-called-up-by-the-lakers/?noredirect=on&amp;utm_term=.77ed308caff9" target="_blank" rel="noopener">This gray-haired 32-year-old rookie spent 10 years in the minors. His NBA debut was too good to believe</a></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;十年饮冰, 难凉热血, 梦还在,黄苍终会眷顾.         –梁启超&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;北京的周五依旧是行人匆匆,夹杂着兮兮小雨,更是显得匆忙与急促.打着雨伞赶着去实验室,继续完成自己调不完的bug,写不完的程序.真是应了实验室同学的调侃”沐风栉雨搞科研”.&lt;br&gt;惯例周五的实验室必定是空空荡荡,无意在微信朋友圈看到好友江转发了一篇关于NBA比赛报道的文章,若不是他配有文字描述”如果足够努力,最差的结果不就是大器晚成”, 还以为又是司空见惯的NBA球场上那些”飞禽猛兽”不可思议的表现.充满着疑问点开了由”虎扑体育”公众号推送的题为”你生涯最高光的时刻是总决赛MVP吗?而我,就是现在了”.看完文章之后,已然哭成一个傻逼样,心情久久不能平复.&lt;br&gt;
    
    </summary>
    
      <category term="人生" scheme="http://yoursite.com/categories/%E4%BA%BA%E7%94%9F/"/>
    
    
      <category term="思考" scheme="http://yoursite.com/tags/%E6%80%9D%E8%80%83/"/>
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2018/07/31/Pytorch%E6%95%99%E7%A8%8B(%E4%B8%80)/"/>
    <id>http://yoursite.com/2018/07/31/Pytorch教程(一)/</id>
    <published>2018-07-31T09:09:11.975Z</published>
    <updated>2017-10-18T21:01:52.000Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="PYTORCH-系列教程（一）"><a href="#PYTORCH-系列教程（一）" class="headerlink" title="PYTORCH 系列教程（一）"></a>PYTORCH 系列教程（一）</h2><p>Author：muzi</p><p><title><center>201_torch_numpy</center></title><br><img src="http://od2s78ez3.bkt.clouddn.com/17-10-19/33138087.jpg" alt=""><br><img src="http://od2s78ez3.bkt.clouddn.com/17-10-19/36291573.jpg" alt=""></p><ol><li><p>将numpy数组转换为张量，或者张量转换为数组<br>(convert numpy to tensor or vise versa 反之亦然)</p><p> code<br> import torch<br> import numpy as np<br> np_data = np.arange(6).reshape((2, 3))<br> print np_data<br> torch_data = torch.from_numpy(np_data)<br> print torch_data<br> tensor2array = torch_data.numpy()<br> print tensor2array<br>结果：</p><p> [[0 1 2]<br>  [3 4 5]]</p><p>  0  1  2<br>  3  4  5<br> [torch.LongTensor of size 2x3]</p><p> [[0 1 2]<br>  [3 4 5]]</p></li><li><p>元素取绝对值</p><p> code<br> data = [-1, -2, 1, 2]<br> print data<br> tensor = torch.FloatTensor(data)<br> print tensor<br> print np.abs(data)<br> print torch.abs(tensor)<br>结果：</p><p> [-1, -2, 1, 2]</p><p> -1<br> -2<br>  1<br>  2<br> [torch.FloatTensor of size 4]</p><p> [1 2 1 2]</p><p>  1<br>  2<br>  1<br>  2<br> [torch.FloatTensor of size 4]</p></li><li><p>元素取sin值</p><p> code<br> print np.sin(data)<br> print torch.sin(tensor)<br>结果：</p><p> [-0.84147098 -0.90929743  0.84147098  0.90929743]</p><p> -0.8415<br> -0.9093<br>  0.8415<br>  0.9093<br> [torch.FloatTensor of size 4]</p></li><li><p>张量元素取sigmoid值</p><p> code<br> print tensor.sigmoid()<br>结果</p><p>  0.2689<br>  0.1192<br>  0.7311<br>  0.8808<br> [torch.FloatTensor of size 4]</p></li><li><p>张量元素取指数值</p><p> code<br> print tensor.exp()<br>结果：</p><p> 0.3679<br> 0.1353<br> 2.7183<br> 7.3891<br>  [torch.FloatTensor of size 4]</p></li><li><p>元素取平均值</p><p> code<br> print np.mean(data)<br> print torch.mean(tensor)<br>结果：</p><p> 0.0<br> 0.0<br>7.列表，张量的矩阵运算</p><p> data = [[1,2], [3,4]]<br> print data<br> print type(data)<br> tensor = torch.FloatTensor(data)<br> print np.matmul(data,data)<br> print type(np.matmul(data,data))<br> print torch.mm(tensor,tensor)<br>结果：</p><p> [[1, 2], [3, 4]]<br> <type 'list'=""></type></p><h1 id="数据类型是list，可以通过matmul计算list的矩阵运算。"><a href="#数据类型是list，可以通过matmul计算list的矩阵运算。" class="headerlink" title="数据类型是list，可以通过matmul计算list的矩阵运算。"></a>数据类型是list，可以通过matmul计算list的矩阵运算。</h1><p> [[ 7 10]<br>  [15 22]]<br> <type 'numpy.ndarray'=""><br>   7  10<br>  15  22<br> [torch.FloatTensor of size 2x2]</type></p></li><li><p>数组的矩阵乘法操作；张量的內积运算</p><p> code<br> data = np.array(data)<br> print data<br> print type(data) #数据类型是数组，可以通过dot操作计算矩阵运算<br> print data.dot(data)<br> tensor = torch.FloatTensor(data)<br> print tensor<br> #print tensor.dot(tensor) #不正确的操作，因为维度不匹配<br> data1 = [1,2,3,4]<br> print type(data1)<br> print type(data1)<br> tensor = torch.FloatTensor(data1)<br> print tensor<br> print tensor.dot(tensor) #正确的操作 进行內积运算<br>结果：</p><p> [[1 2]<br>  [3 4]]<br> <type 'numpy.ndarray'=""><br> [[ 7 10]<br>  [15 22]]</type></p><p>  1  2<br>  3  4<br> [torch.FloatTensor of size 2x2]</p><p> [1, 2, 3, 4]</p> <type 'list'=""><p>  1<br>  2<br>  3<br>  4<br> [torch.FloatTensor of size 4]</p><p> 30.0</p></type></li><li><p>张量对应元素相乘</p><p> data =[[1,2],[3,4]]<br> print data<br> print type(data)<br> data = np.array(data)<br> print data        # 数据类型：列表与数组区别<br> print type(data)<br> tensor = torch.FloatTensor(data)<br> print tensor.mm(tensor)<br> print tensor*tensor          # 张量元素的对应乘积<br> data1 = np.arange(1,5)<br> data2 = np.array([1,2,3,4])  # 两种方式 产生(n,)的数组<br> print data1<br> print data2<br> print type(data1)<br> print data1.shape<br> tensor_1D = torch.FloatTensor(data1)<br> tensor_1D_ = torch.from_numpy(data2)   #两种方式 将（n,）的数组转换为 1-D张量<br> print tensor_1D<br> print tensor_1D.dot(tensor_1D)         # 1-D张量类型数据的內积：对应元素相乘求和<br>结果：</p><p> [[1, 2], [3, 4]]<br> <type 'list'=""><br> [[1 2]<br>  [3 4]]<br> <type 'numpy.ndarray'="">    #列表与数组的区别</type></type></p><p>   7  10<br>  15  22<br> [torch.FloatTensor of size 2x2]   #张量矩阵乘法</p></li></ol><pre><code>  1   4  9  16[torch.FloatTensor of size 2x2]  #张量对应元素相乘[1 2 3 4][1 2 3 4]&lt;type &apos;numpy.ndarray&apos;&gt;(4,) 1 2 3 4[torch.FloatTensor of size 4]&lt;class &apos;torch.FloatTensor&apos;&gt;30.0</code></pre><p>Reference :<br><a href="https://github.com/MorvanZhou/PyTorch-Tutorial" target="_blank" rel="noopener">莫烦：pytorch教程</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;hr&gt;
&lt;h2 id=&quot;PYTORCH-系列教程（一）&quot;&gt;&lt;a href=&quot;#PYTORCH-系列教程（一）&quot; class=&quot;headerlink&quot; title=&quot;PYTORCH 系列教程（一）&quot;&gt;&lt;/a&gt;PYTORCH 系列教程（一）&lt;/h2&gt;&lt;p&gt;Author：muzi&lt;/
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://yoursite.com/2018/07/31/hello-world/"/>
    <id>http://yoursite.com/2018/07/31/hello-world/</id>
    <published>2018-07-31T08:25:38.829Z</published>
    <updated>2018-07-31T08:25:38.829Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Generative Adversarial Networks</title>
    <link href="http://yoursite.com/2016/11/27/2016-11-27-gans/"/>
    <id>http://yoursite.com/2016/11/27/2016-11-27-gans/</id>
    <published>2016-11-27T02:00:00.000Z</published>
    <updated>2018-04-24T18:09:04.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xritj.com1.z0.glb.clouddn.com/public/16-11-27/13513902.jpg" alt=""><br><a id="more"></a></p><p>人工智能目前的核心目标应该是赋予机器自主理解我们所在世界的能力。对于人类来说，我们对这个世界所了解的知识可能很快就会忘记，比如我们所处的三维环境中，物体能够交互，移动，碰撞；什么动物会飞，什么动物吃草等等。这些巨大的并且不断扩大的信息现在是很容易被机器获取的，问题的关键是怎么设计模型和算法让机器更好的去分析和理解这些数据中所蕴含的宝藏。</p><p><code>Generative models</code>(生成模型)现在被认为是能够实现这一目标的最有前景的方法之一。<code>Generative models</code>通过输入一大堆特定领域的数据进行训练（比如图像，句子，声音等）来使得模型能够产生和输入数据相似的输出。这一直觉的背后可以由下面名言阐述。</p><blockquote><p>“What I cannot create, I do not understand.”  —Richard Feynman</p></blockquote><p>生成模型由一个参数数量比训练数据少的多神经网络构成，所以生成模型为了能够产生和训练数据相似的输出就会迫使自己去发现数据中内在的本质内容。训练<code>Generative models</code>的方法有几种，在这里我们主要阐述其中的<code>Adversarial Training</code>（对抗训练）方法。</p><h2 id="Adversarial-Training"><a href="#Adversarial-Training" class="headerlink" title="Adversarial Training"></a>Adversarial Training</h2><p>上文说过Adversarial Training是训练生成模型的一种方法。为了训练生成模型，Adversarial Training提出一种<code>Discriminative Model</code>(判别模型)来和生成模型产生对抗，下面来说说<code>Generative models</code> $G(z)$ 和 <code>Discriminative Model</code> $D(x)$ 是如何相互作用的。</p><ul><li>生成模型的目标是模仿输入训练数据, 通过输入一个随机噪声来产生和训练数据相似的样本；</li><li>判别模型的目标就是判断生成模型产生的样本和真实的输入样本之间的相似性。</li></ul><p>其中生成模型和判别模型合起来的框架被称为<code>GAN</code>网络。通过下图我们来理清判别模型和生成模型之间的输入输出关系：生成模型通过输入随机噪声 $z(z \sim p_z)$ 产生合成样本；而判别模型通过分别输入真实的训练数据和生成模型的训练数据来判断输入的数据是否真实。</p><center><br><img src="https://culurciello.github.io/assets/unsup/gan_simple.svg" alt=""><br></center><p>描述了<code>GAN</code>的网络结构，但它的优化目标是什么？怎么就可以通过训练使得生成模型能够产生和真实数据相似的输出？优化的目标其实很简单，简单来说就是：</p><ul><li>判别模型努力的想把真实的数据预测为<code>1</code>，把生成的数据预测为<code>0</code>；</li><li>而生成模型的奋斗目标则为‘我’要尽力的让判别模型对‘我’生成的数据预测为<code>1</code>，让判别模型分不清‘我’产生的数据和真实数据之间的区别，从而达到‘以假乱真’的效果。</li></ul><p>下面用形式化说明下如果训练GAN网络, 先定义一些参数：</p><table><thead><tr><th style="text-align:center">参数</th><th style="text-align:center">含义</th></tr></thead><tbody><tr><td style="text-align:center">$p_z$</td><td style="text-align:center">输入随机噪声 $z$ 的分布</td></tr><tr><td style="text-align:center">$p_{data}$</td><td style="text-align:center">未知的输入样本的数据分布</td></tr><tr><td style="text-align:center">$p_g$</td><td style="text-align:center">生成模型的输出样本的数据分布，GAN的目标就是要$p_g=p_{data}$</td></tr></tbody></table><p>训练判别模型 $D(x)$ 的目标：</p><ol><li>对每一个输入数据 $x \sim p_{data}$ 要使得 $D(x)$ 最大；</li><li>对每一个输入数据 $x \nsim p_{data}$ 要使得 $D(x)$ 最小。</li></ol><p>训练生成模型 $G(z)$ 的目标是来产生样本来欺骗判别模型 $D$, 因此目标为最大化 $D(G(z))$，也就是把生成模型的输出输入到判别模型，然后要让判别模型预测其为真实数据。同时，最大化 $D(G(z))$ 等同于最小化 $1-D(G(z))$，因为 $D$ 的输出是介于0到1之间的，真实数据努力预测为1，否则为0。</p><p>所以把生成模型和判别模型的训练目标结合起来，就得到了<code>GAN</code>的优化目标：</p><p>$$\min_G \max_D {\mathbb E}<em>{x\sim p</em>{\rm data}} \log D(x)+{\mathbb E}_{z\sim p_z}[\log (1-D(G(z)))] $$</p><p>总结一下上面的内容，GAN启发自博弈论中的二人零和博弈，在二人零和博弈中，两位博弈方的利益之和为零或一个常数，即一方有所得，另一方必有所失。GAN模型中的两位博弈方分别由生成模型和判别模型充当。生成模型G捕捉样本数据的分布，判别模型是一个二分类器，估计一个样本来自于训练数据（而非生成数据）的概率。G和D一般都是非线性映射函数，例如多层感知机、卷积神经网络等。生成模型的输入是一些服从某一简单分布（例如高斯分布）的随机噪声z，输出是与训练图像相同尺寸的生成图像。向判别模型D输入生成样本，对于D来说期望输出低概率（判断为生成样本），对于生成模型G来说要尽量欺骗D，使判别模型输出高概率（误判为真实样本），从而形成竞争与对抗。</p><h2 id="GAN实现"><a href="#GAN实现" class="headerlink" title="GAN实现"></a>GAN实现</h2><p>一个简单的一维数据GAN网络的tensorflow实现:<a href="https://github.com/ericjang/genadv_tutorial" target="_blank" rel="noopener">genadv_tutorial</a><br>其一维训练数据分布如下所示，是一个均值-1， $\sigma =1$ 的正态分布。</p><center><br><img src="http://7xritj.com1.z0.glb.clouddn.com/public/16-11-24/4360345.jpg" alt=""><br></center><p>我们结合代码和上面的理论内容来分析下GAN的具体实现，判别模型的优化目标为最大化下式，其中 $D_1(x)$ 表示判别真实数据, $D_2(G(z))$ 表示对生成的数据进行判别， 其中 $D_1$ 和 $D_2$ 是共享参数的， 也就是说是同一个判别模型。</p><p>$$\log(D_1(x))+\log(1-D_2(G(z)))$$</p><p>对应的python代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">batch=tf.Variable(<span class="number">0</span>)</span><br><span class="line">obj_d=tf.reduce_mean(tf.log(D1)+tf.log(<span class="number">1</span>-D2))</span><br><span class="line">opt_d=tf.train.GradientDescentOptimizer(<span class="number">0.01</span>)</span><br><span class="line">              .minimize(<span class="number">1</span>-obj_d,global_step=batch,var_list=theta_d)</span><br></pre></td></tr></table></figure></p><p>为了优化 $G$, 我们想要最大化 $D_2(x’)$(成功欺骗 $D$ )，因此 $G$ 的优化函数为：</p><p>$$\log(D_2(G(z)))$$</p><p>对应的python代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">batch=tf.Variable(<span class="number">0</span>)</span><br><span class="line">obj_g=tf.reduce_mean(tf.log(D2))</span><br><span class="line">opt_g=tf.train.GradientDescentOptimizer(<span class="number">0.01</span>)</span><br><span class="line">              .minimize(<span class="number">1</span>-obj_g,global_step=batch,var_list=theta_g)</span><br></pre></td></tr></table></figure><p>定义好优化目标后，下面就是训练的主要代码了：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Algorithm 1, GoodFellow et al. 2014</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(TRAIN_ITERS):</span><br><span class="line">    x= np.random.normal(mu,sigma,M) <span class="comment"># sample minibatch from p_data</span></span><br><span class="line">    z= np.random.random(M)  <span class="comment"># sample minibatch from noise prior</span></span><br><span class="line">    sess.run(opt_d, &#123;x_node: x, z_node: z&#125;) <span class="comment"># update discriminator D</span></span><br><span class="line">    z= np.random.random(M) <span class="comment"># sample noise prior</span></span><br><span class="line">    sess.run(opt_g, &#123;z_node: z&#125;) <span class="comment"># update generator G</span></span><br></pre></td></tr></table></figure></p><p>下面是实验的结果，左图是训练之间的数据，可以看到生成数据的分布和训练数据相差甚远；右图是训练后的数据分析，生成数据和训练数据的分布接近了很多，且此时判别模型的输出分布在0.5左右，说明生成模型顺利的欺骗到判别模型。</p><figure><br>    <img src="http://7xritj.com1.z0.glb.clouddn.com/public/16-11-29/64984825.jpg"><br><br></figure><h2 id="DCGAN"><a href="#DCGAN" class="headerlink" title="DCGAN"></a>DCGAN</h2><p>GAN的一个改进模型就是DCGAN。这个网络的生成模型的输入为一个100个符合均匀分布的随机数（通常被称为<code>code</code>），然后产生输出为64x64x3的输出图像(下图中 $G(z)$ ), 当<code>code</code>逐渐递增时，生成模型输出的图像也逐渐变化。下图中的生产模型主要由<a href="http://buptldy.github.io/2016/10/29/2016-10-29-deconv/" target="_blank" rel="noopener">反卷积层</a>构成, 判别模型就由简单的卷积层组成，最后输出一个判断输入图片是否为真实数据的概率 $P(x)$ 。</p><center><br><img src="http://7xritj.com1.z0.glb.clouddn.com/public/16-11-27/33141448.jpg"><br></center><p>下图为随着迭代次数，DCGAN产生图像的变化过程。</p><center><br><img src="https://openai.com/assets/research/generative-models/learning-gan-ffc4c09e6079283f334b2485ae663a6587d937a45ebc1d8aeac23a67889a3cf5.gif"><br></center><p>训练好网络之后，其中的生成模型和判别模型都有其他的作用。一个训练好的判别模型能够用来对数据提取特征然后进行分类任务。通过输入随机向量生成模型可以产生一些非常有意思的的图片，如下图所示，当输入空间平滑变化时，输出的图片也在平滑转变。</p><center><br><img src="http://7xritj.com1.z0.glb.clouddn.com/public/16-11-25/42718244.jpg"><br></center><p>还有一个非常有意思的属性就是如果对生产模型的输入向量做一些简单的数学运算，那么学习的特征输出也有同样的性质，如下图所示。</p><center><br><img src="https://fb-s-a-a.akamaihd.net/h-ak-xfp1/t39.2365-6/13438466_275356996149902_2140145659_n.jpg"><br></center><h2 id="GAN的训练及其改进"><a href="#GAN的训练及其改进" class="headerlink" title="GAN的训练及其改进"></a>GAN的训练及其改进</h2><p>上面使用GAN产生的图像虽然效果不错，但其实GAN网络的训练过程是非常不稳定的。<br>通常在实际训练GAN中所碰到的一个问题就是判别模型的收敛速度要比生成模型的收敛速度要快很多，通常的做法就是让生成模型多训练几次来赶上生成模型，但是存在的一个问题就是通常生成模型和判别模型的训练是相辅相成的，理想的状态是让生成模型和判别模型在每次的训练过程中同时变得更好。判别模型理想的minimum loss应该为0.5，这样才说明判别模型分不出是真实数据还是生成模型产生的数据。</p><h3 id="Improved-GANs"><a href="#Improved-GANs" class="headerlink" title="Improved GANs"></a>Improved GANs</h3><p><a href="https://arxiv.org/pdf/1606.03498v1.pdf" target="_blank" rel="noopener">Improved techniques for training GANs</a>这篇文章提出了很多改进GANs训练的方法，其中提出一个想法叫<code>Feature matching</code>，之前判别模型只判别输入数据是来自真实数据还是生成模型。现在为判别模型提出了一个新的目标函数来判别生成模型产生图像的统计信息是否和真实数据的相似。让 $f(x)$ 表示判别模型中间层的输出， 新的目标函数被定义为 $|| \mathbb{E}<em>{x \sim p</em>{data}}f(x)  -  \mathbb{E}_{z \sim p_z}f(G(z))||^2_2$, 其实就是要求真实图像和合成图像在判别模型中间层的距离要最小。这样可以防止生成模型在当前判别模型上过拟合。</p><h3 id="InfoGAN"><a href="#InfoGAN" class="headerlink" title="InfoGAN"></a>InfoGAN</h3><p>到这可能有些同学会想到，我要是想通过GAN产生我想要的特定属性的图片改怎么办？普通的GAN输入的是随机的噪声，输出也是与之对应的随机图片，我们并不能控制输出噪声和输出图片的对应关系。这样在训练的过程中也会倒置生成模型倾向于产生更容易欺骗判别模型的某一类特定图片，而不是更好的去学习训练数据的分布，这样对模型的训练肯定是不好的。InfoGAN的提出就是为了解决这一问题，通过对输入噪声添加一些类别信息以及控制图像特征(如mnist数字的角度和厚度)的隐含变量来使得生成模型的输入不在是随机噪声。虽然现在输入不再是随机噪声，但是生成模型可能会忽略这些输入的额外信息还是把输入当成和输出无关的噪声，所以需要定义一个生成模型输入输出的互信息，互信息越高，说明输入输出的关联越大。</p><p>下面三张图片展示了通过分别控制输入噪声的类别信息，数字角度信息，数字笔画厚度信息产生指定输出的图片，可以看出InfoGAN产生图片的效果还是很好的。</p><center><br><img src="http://7xritj.com1.z0.glb.clouddn.com/public/16-11-29/839516.jpg"><br><img src="http://7xritj.com1.z0.glb.clouddn.com/public/16-11-29/10937636.jpg"><br><img src="http://7xritj.com1.z0.glb.clouddn.com/public/16-11-29/2995738.jpg"><br></center><h3 id="其他应用"><a href="#其他应用" class="headerlink" title="其他应用"></a>其他应用</h3><p>GAN网络还有很多其他的有趣应用，比如下图所示的根据<code>一句话来产生对应的图片</code>，可能大家都有了解karpathy大神的<a href="https://github.com/karpathy/neuraltalk2" target="_blank" rel="noopener"><code>看图说话</code></a>, 但是GAN有能力把这个过程给反过来。</p><center><br><img src="http://7xritj.com1.z0.glb.clouddn.com/public/16-11-29/51572272.jpg"><br></center><p>还有下面这个“<a href="https://github.com/bamos/dcgan-completion.tensorflow" target="_blank" rel="noopener">图像补全</a>”, 根据图像剩余的信息来匹配最佳的补全内容。</p><center><br><img src="https://github.com/bamos/dcgan-completion.tensorflow/raw/master/completion.compressed.gif"><br></center><p>还有下面这个<a href="https://swarbrickjones.wordpress.com/2016/01/13/enhancing-images-using-deep-convolutional-generative-adversarial-networks-dcgans/" target="_blank" rel="noopener">图像增强</a>的例子，有点去马赛克的意思，效果还是挺不错的:-D。</p><center><br><img src="http://7xritj.com1.z0.glb.clouddn.com/public/16-11-29/71438836.jpg"><br></center><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>颜乐存说过，2016年深度学习领域最让他兴奋技术莫过于对抗学习。对抗学习确实是解决非监督学习的一个有效方法，而无监督学习一直都是人工智能领域研究者所孜孜追求的“终极目标”之一。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://arxiv.org/abs/1406.2661" target="_blank" rel="noopener">Generative Adversarial Networks</a></p><p><a href="https://arxiv.org/abs/1511.06434" target="_blank" rel="noopener">Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</a></p><p><a href="https://arxiv.org/abs/1606.03498" target="_blank" rel="noopener">Improved Techniques for Training GANs</a></p><p><a href="https://arxiv.org/abs/1606.03657" target="_blank" rel="noopener">InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xritj.com1.z0.glb.clouddn.com/public/16-11-27/13513902.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="Deep Learning" scheme="http://yoursite.com/tags/Deep-Learning/"/>
    
      <category term="Unsupervised Learning" scheme="http://yoursite.com/tags/Unsupervised-Learning/"/>
    
  </entry>
  
</feed>
